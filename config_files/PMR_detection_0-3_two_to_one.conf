#!/bin/bash 

# ------------------ logging details ------------------
session_name="PMR_detection_0-3_two_to_one" # prefix the logging directory with this name
#log_dest="" # name of directory with logging info (stats, train model, parameters, etc.)

# ------------------ dataset details ------------------
root_dir="/data/perception-working/Geffen/avec_data/" # full path to dataset directory
train_data_dir="none" # specify if training data is in another directory within root_dir
val_data_dir="none" # specify if validation data is in another directory within root_dir
#test_data_dir="test_data" # specify if test data is in another directory within root_dir
train_labels_csv="binary_train_metadata_two_to_one.csv" # file name of csv with training labels and/or metadata
val_labels_csv="binary_val_metadata_two_to_one.csv" # file name of csv with validation labels and/or metadata
#test_labels_csv="test_labels2.csv"
pred_labels="binary_sampled_val_metadata.csv" # used with predict.py

# ------------------ training details ------------------
gpu_i=0 # (int) GPU instance to use (0, 1, 2, etc.)
model_name="PMRfusionNN" # name of the model class (torch.nn.Module)
optim="RMS" # name of PyTorch optimizer to use
loss_freq=10 # (int) print the loss every nth batch
val_freq=0 # (int) do a validation pass every nth batch (if set to zero, do each epoch)

# ------------------ hyperparameters ------------------
batch_size=32 # what size batch to use (32, 64, 128, etc.)
lr=0.002 # (float) learning rate
hidden_size=64 # dimension of hidden state (RNN)
classification="y" # use the model for classification (y/n) 
num_classes=2 # number of classes for the task, IF REGRESSION SET TO (-1)
regression="n" # use the model for regression (y/n)
input_size=23 # dimension of input features (e.g. MFCC features = 26)
num_layers=1 # number of GRU layers
num_epochs=5 # number of times to go through entire training set
normalize="y" # normalize input features (y/n)
hidden_init_rand="n" # initialize the hidden state with random values, otherwise use zeros (y/n)
weighted_loss="n" # weight loss function based on imbalanced classes (y/n), weights calculated from dataset
imbalanced_sampler="n" # use an imbalanced sampler to rebalance class distribution per batch (y/n)
l2_reg="n" # do l2 regularization (y/n)
weight_decay_amnt=0 # weight decay constant for l2 regularization (float)
dropout="n" # use dropout before fully connected layer (y/n)
dropout_prob=0 # droput probability (float)

# ------------------ extra optional ------------------
load_trained="n"
trained_path="none"
